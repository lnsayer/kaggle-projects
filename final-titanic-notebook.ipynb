{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30664,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import libraries","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport sklearn\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-19T13:54:32.696443Z","iopub.execute_input":"2024-03-19T13:54:32.697071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import train, test, gender submission dataframes and visualise data","metadata":{}},{"cell_type":"code","source":"# Load the data\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ngender_submission = pd.read_csv(\"/kaggle/input/titanic/gender_submission.csv\")\n\n# Make a dataframe\ntrain_df = pd.DataFrame(train_data)\ntest_df = pd.DataFrame(test_data)\ncombined_df = pd.concat([train_df,test_df], ignore_index=True)\n\n# Set how many rows are set in the dataframe\npd.set_option('display.min_rows', 10) \npd.set_option('display.max_rows', 10) \n\n# Show the dataframe\ndisplay(test_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualise differences between male and female survival rates at different ages","metadata":{}},{"cell_type":"code","source":"# Dataframes of male and female survivals\nmale_train_df = train_df.loc[train_df['Sex'] == 'male']\nfemale_train_df = train_df.loc[train_df['Sex'] == 'female']\n\nmale_survived_df = male_train_df.loc[male_train_df['Survived'] == 1]\nmale_died_df = male_train_df.loc[male_train_df['Survived'] == 0]\n\nfemale_survived_df = female_train_df.loc[female_train_df['Survived'] == 1]\nfemale_died_df = female_train_df.loc[female_train_df['Survived'] == 0]\n\n# Initiating the plots\nfig, (ax0,ax1) = plt.subplots(nrows=1, ncols=2, figsize=(14,6), sharex=True)\n\n# Male and female survived histograms, respectively\nhistogram_male_survived = ax0.hist(male_survived_df['Age'], bins=20, alpha=0.5,  label='Survived', color='C0', zorder=1);\nhistogram_male_died = ax0.hist(male_died_df['Age'], bins=20, alpha=0.5,  label='Died', color='C1', zorder=0);\n\nhistogram_female_survived = ax1.hist(female_survived_df['Age'], bins=20, alpha=0.5,  label='Survived');\nhistogram_female_died = ax1.hist(female_died_df['Age'], bins=20, alpha=0.5,  label='Died');\n\n# Add a legend to ax0\nax0.legend()\nax1.legend()\n# Set titles\nax0.set(title='Male', xlabel='Age', ylabel='Number of people');\nax1.set(title='Female', xlabel='Age', ylabel='Number of people');\n# Set labels\nax0.set_xlabel('Age (yrs)', fontsize = 12)\nax0.set_ylabel('Number of people', fontsize = 12)\nax1.set_xlabel('Age (yrs)', fontsize = 12)\nax1.set_ylabel('Number of people', fontsize = 12)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualise survival rates at different fare prices ","metadata":{}},{"cell_type":"code","source":"# Plot histograms of the Number who survived/died according to fare price\nsurvived_df = train_df.loc[train_df['Survived'] == 1]\ndied_df = train_df.loc[train_df['Survived'] == 0]\n\n# Initiating the figures\nfig, ax = plt.subplots(figsize=(14,6))\n\n# Histograms of the survived and died based on fare price\nsurvived_hist = ax.hist(survived_df['Fare'], bins=20, alpha=0.5,  label='Survived', color='C0', zorder=0);\ndied_ = ax.hist(died_df['Fare'], bins=20, alpha=0.5,  label='Died', color='C1', zorder=1);\n\n# Add a legend to ax0\nax.legend()\n# Set labels\nax.set_xlabel('Fare ($)', fontsize = 12)\nax.set_ylabel('Number of people', fontsize = 12)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Functions to perform feature engineering\n##### `replace_titles` allocates uncommon titles (e.g Major, Capt etc.) to broader title categories (e.g Mr, Ms etc)\n##### `replace_cabin` replaces the cabin codes of passengers with their deck section, denoted by a letter \n##### `add_family` creates a new feature family size which is the total number of siblings/parents/children of a passenger","metadata":{}},{"cell_type":"code","source":"import re \n\n# New data frame to work with\nnew_train_df = train_df.copy(deep=True)\n\n# Function to create a new column with the title of each passenger\nnew_train_df['Title'] = new_train_df['Name'].map(lambda x: re.compile(\", (.*?)\\.\").findall(x)[0])\n\n# Function to allocate uncommon titles to broader title categories\ndef replace_titles(x):\n    title=x['Title']\n    if title in ['Don', 'Major', 'Capt', 'Jonkheer', 'Rev', 'Col', 'Sir']:\n        return 'Mr'\n    elif title in ['the Countess', 'Mme', 'Lady', 'Dona']:\n        return 'Mrs'\n    elif title in ['Mlle', 'Ms']:\n        return 'Miss'\n    elif title =='Dr':\n        if x['Sex']=='Male':\n            return 'Mr'\n        else:\n            return 'Mrs'\n    else:\n        return title\n\ndeck = {\"A\": \"A\", \"B\": \"B\", \"C\": \"C\", \"D\": \"D\", \"E\": \"E\", \"F\": \"F\", \"G\": \"G\", \"U\": \"U\"}\n\n# Function to replace the cabin code with their deck section, denoted by a letter\ndef replace_cabin(x):\n    x['Cabin'] = x['Cabin'].fillna(\"U0\")\n    x['Deck'] = x['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\n    x['Deck'] = x['Deck'].map(deck)\n    x['Deck'] = x['Deck'].fillna(\"U\")\n    x.drop('Cabin',axis=1, inplace=True)\n    \n    return x\n\n# Function to define a person's family size\ndef add_family(x):\n    x['Familysize'] = x['SibSp']+x['Parch']+1\n    return x\n\n# Show the new altered dataframes with 'Title' and 'Deck' columns\nnew_train_df['Title']=new_train_df.apply(replace_titles, axis=1)\nnew_train_df= replace_cabin(new_train_df)\nnew_train_df = add_family(new_train_df)\n\nnew_train_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Function `prepare_dataframe` \n#### It performs all the feature engineering to a dataframe. It uses the previous functions to create new features and imputes missing values","metadata":{}},{"cell_type":"code","source":"# Import the methods for pipeline processing\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.impute import KNNImputer\n\n# Function to take a dataframe and prepare it for training. It imputes (fills missing values) for\"Age\" and \"Fare\", \n# makes the \"Cabin\" and \"Sex\" column binary (i.e in a cabin or not, male or female) and one hot encodes the \"Embarked\",\n# \"Title\" and \"Deck\" column. \n\ndef prepare_dataframe(df, drop_columns):\n    # Copying dataframe to manipulate\n    new_df = df.copy(deep=True)\n    \n    # Binary mapping the sex column\n    binary_mapping = {\"male\" : 0, \"female\": 1}\n    new_df[\"Sex\"] = new_df[\"Sex\"].map(binary_mapping)\n    \n    # Creating the new Title and Deck columns\n    new_df['Title'] = new_df['Name'].map(lambda x: re.compile(\", (.*?)\\.\").findall(x)[0])\n    new_df['Title'] = new_df.apply(replace_titles, axis=1)\n    \n    # Add a column with their deck section\n    new_df = replace_cabin(new_df)\n    # Add a column with their family size\n    new_df = add_family(new_df)\n    \n    # Numeric and categorical features to encode\n    numeric_features = [\"Fare\"]\n    categorical_features = [\"Embarked\", \"Title\", \"Deck\", 'Pclass']\n    \n    # Strategies for transforming these features\n    numeric_transformer = Pipeline(steps = [(\"imputer\", SimpleImputer(strategy=\"median\"))])\n    \n    categorical_transformer = Pipeline(steps = [ (\"imputer\", SimpleImputer(strategy = \"constant\", \n                                                                           fill_value=\"missing\")),\n                                               (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))])\n    # Transforming these features    \n    preprocessor = ColumnTransformer(transformers = [(\"num\", numeric_transformer, numeric_features),\n                                                    (\"cat\", categorical_transformer, categorical_features)])\n    \n    preprocessor.fit(new_df)\n    \n    transformed_data = preprocessor.transform(new_df)\n    \n    # Getting transformed data and creating new columns to put them in \n    numeric_data = transformed_data[:, :len(numeric_features)].toarray()\n    categorical_data = transformed_data[:, len(numeric_features):].toarray()\n        \n    categorical_encoded_features = preprocessor.named_transformers_['cat']['onehot'] \\\n                                    .get_feature_names_out(input_features=categorical_features)\n    \n    # Replace the columns with transformed data\n    new_df[categorical_encoded_features] = categorical_data\n    new_df[numeric_features] = numeric_data\n    \n    # Impute the missing age data using a KNN algorithm utilising the following features \n    X = new_df[['SibSp', 'Fare', 'Age', 'Title_Master', 'Title_Miss',\n       'Title_Mr', 'Title_Mrs', 'Pclass', 'Sex']]\n\n    impute_knn = KNNImputer()\n    X_imputed = impute_knn.fit_transform(X)\n\n    X_df = pd.DataFrame(X_imputed)\n    age_column = X_df.iloc[:,2]\n    new_df['Age'] = age_column\n    \n    \n    # Removing obsolete features which have been transformed \n    if \"Embarked_missing\" in new_df.columns:\n        new_df.drop(\"Embarked_missing\", axis=1, inplace=True)\n    if \"Title\" in new_df.columns:\n        new_df.drop(\"Title\", axis=1, inplace=True)\n    if \"Deck\" in new_df.columns:\n        new_df.drop(\"Deck\", axis=1, inplace=True)\n    if \"Pclass\" in new_df.columns:\n        new_df.drop(\"Pclass\", axis=1, inplace=True)\n        \n    # Dropping custom columns according to which features we want to include in a model\n    new_df.drop(drop_columns,axis =1, inplace=True)\n    \n    return pd.DataFrame(new_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualise the new dataframe","metadata":{}},{"cell_type":"code","source":"# Custom columns to drop in the function prepare_dataframe\ndrop_columns = [\"Embarked\", \"Ticket\", \"Name\"]\nnew_train_df = prepare_dataframe(train_df, drop_columns)\n# display(new_train_df)\nprint(new_train_df.columns)\nnew_train_df['Age'].isna().sum()\nnew_train_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualise the age distributions of the original dataframe (with 177 values missing) and imputed dataframe (using KNN)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:45:25.694631Z","iopub.execute_input":"2024-03-19T11:45:25.695111Z","iopub.status.idle":"2024-03-19T11:45:25.700640Z","shell.execute_reply.started":"2024-03-19T11:45:25.695076Z","shell.execute_reply":"2024-03-19T11:45:25.699472Z"}}},{"cell_type":"code","source":"# Columns to drop in preparing the dataframes\ndrop_columns = [\"Embarked\", \"Ticket\", \"Name\", 'PassengerId']\n\nnew_train_df = prepare_dataframe(train_df, drop_columns)\nnew_test_df = prepare_dataframe(test_df, drop_columns)\n\n#Plotting histograms of the feature variables\nfig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2, figsize = (8,5))\n\n# Create histograms\nax0.hist(train_df[\"Age\"], bins=20);\nax1.hist(new_train_df[\"Age\"], bins=20);\n\n# Set labels\nax0.set_xlabel('Age (yrs)', fontsize = 12)\nax0.set_ylabel('Number of people', fontsize = 12)\nax1.set_xlabel('Age (yrs)', fontsize = 12)\nax0.set_title('Original dataframe')\nax1.set_title('Imputed dataframe')\n\nprint(new_train_df[\"Age\"].isna().sum())\nprint(train_df[\"Age\"].isna().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Quick fitting of the data with a default Random forest classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n# Setup the random seed\nnp.random.seed(42)\n\n# Prepare dataframes\nnew_train_df = prepare_dataframe(train_df, drop_columns)\nnew_test_df = prepare_dataframe(test_df, drop_columns)\n\n# First RandomForestClassifier \n\n# Split up into feature variables and target variables\nx_train = new_train_df.drop([\"Survived\"], axis=1)\ny_train = new_train_df[\"Survived\"]\nx_test = new_test_df\n\n# Import randomforestclassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Instantiate the classifier\nclf = RandomForestClassifier(n_estimators=100)\nclf.fit(x_train, y_train)\n\n# Predictions of the training data\ny_preds = clf.predict(x_train)\n\nprint(accuracy_score(y_preds, y_train))\nprint(clf.get_params())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualise the feature importance of the Random forest classifier","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:47:09.399843Z","iopub.execute_input":"2024-03-19T11:47:09.400281Z","iopub.status.idle":"2024-03-19T11:47:09.406481Z","shell.execute_reply.started":"2024-03-19T11:47:09.400251Z","shell.execute_reply":"2024-03-19T11:47:09.404994Z"}}},{"cell_type":"code","source":"# Gives the importance of different features of the model\nimportance = clf.feature_importances_\n\n# Shortened columns to appear on one plot\ncolumns = x_train.columns\n\n# The importance of the different feautures according to the model\nimportance_dictionary = {columns[i] : importance[i] for i in range(len(importance)) }\nimportance\n\nkeys = importance_dictionary.keys()\nvalues = importance_dictionary.values()\n\n# Plotting the feature importance\nplt.figure(figsize=(16, 6))\nplt.bar(keys, values)\nplt.xlabel('Features', size=14)\nplt.ylabel('Feature Importances', size=14)\nplt.xticks(rotation=45)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exhaustive grid search of the optimal hyperparameters for a random forest classifier, using cross-validation to minimise overfitting","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:48:53.341156Z","iopub.execute_input":"2024-03-19T11:48:53.341626Z","iopub.status.idle":"2024-03-19T11:48:53.347178Z","shell.execute_reply.started":"2024-03-19T11:48:53.341592Z","shell.execute_reply":"2024-03-19T11:48:53.345974Z"}}},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import GridSearchCV\n\n# Setup the random seed \nnp.random.seed(42)\n\n# # Random forest model discluding all the features below\ndrop_columns_decks = [\"Embarked\", \"Ticket\", \"Name\", 'PassengerId']\n\n# Print which columns we are including \nprint(set(train_df.columns)-set(drop_columns_decks))\n\n# Grid of hyperparameters to sample from\ngrid = {\n    'n_estimators': [100, 500, 1000],\n    'max_depth': [None, 10, 20, 40],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4, 10],\n    'max_features': ['sqrt'],\n    'bootstrap': [True, False]\n}\n\n# Creating dataframes discluding the titles\nx_train_decks = prepare_dataframe(train_df, drop_columns_decks).drop([\"Survived\"], axis=1)\ny_train = new_train_df[\"Survived\"]\nx_test_decks = prepare_dataframe(test_df, drop_columns_decks)\n\n# Instantiating the Random Forest Classifier\nclf = RandomForestClassifier(n_jobs = 1)\n\n# Setting up randomised search of hyperparameters (considers 10 combinations) with cross validation\n'''\nrs_clf_decks = RandomizedSearchCV(estimator = clf, param_distributions=grid,\n                       n_iter = 10, # number of models to try\n                       cv = 5, # Setting the test set as the validation set\n                       verbose =2 # Prints out information as it is running\n                       )\n'''\n'''\n# Setting up exhaustive grid search of hyperparameters (considers 288 combinations) with cross validation\ngs_clf_decks = GridSearchCV(estimator = clf, param_grid=grid,\n                       cv = 5, # Setting the test set as the validation set\n                       verbose =1 # Prints out information as it is running\n                       )\n\n# Fit the classifier\ngs_clf_decks.fit(x_train_decks, y_train);\n# Best parameters of the 10 iterations\nbest_params_decks = gs_clf_decks.best_params_\n# Dataframe of the results of each hyperparameter combination\ncv_results_decks = gs_clf_decks.cv_results_\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Obtain best hyperparameters of the grid search and visualise the feature importances of the best RF classifier","metadata":{}},{"cell_type":"code","source":"'''\n# Results of the cross validation\nprint(best_params_decks)\nprint(cv_results_decks[\"mean_test_score\"].mean())\n\n# Dataframe results of the 10 iterations\ncv_results_decks_df = pd.DataFrame(cv_results_decks)\ndisplay(cv_results_decks_df)\n\nimportance = gs_clf_decks.best_estimator_.feature_importances_\n\n# Custom columns to fit in the plot (previous labels too long)\ncolumns = x_train_decks.columns\n\n# Feature importances according to the classifier\nimportance_dictionary = {columns[i] : importance[i] for i in range(len(importance)) }\nimportance\n\nkeys = importance_dictionary.keys()\nvalues = importance_dictionary.values()\n\n# Plot the feature importance\nplt.figure(figsize=(17, 6))\nplt.bar(keys, values)\nplt.xlabel('Features')\nplt.ylabel('Feature Importances')\nplt.title('Feature importance')\nplt.show()\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Perform cross validation with only one hyperparameter combination to quickly see the improvements of any new feature engineering. \n### Can use the default hyperparameters or optimal ones\n","metadata":{}},{"cell_type":"code","source":"np.random.seed(42)\n# Run cross validation on the best hyperparameters to test feature engineering \ndrop_columns_decks = [\"Embarked\", \"Ticket\", \"Name\", 'PassengerId']\n\n# Best hyperparameters according to grid search \ngrid = {\n    'bootstrap': [True], 'max_depth': [10], 'max_features': ['sqrt'],\n                                      'min_samples_leaf': [4], 'min_samples_split': [2], 'n_estimators': [100]\n}\n# Hyperparameters used by default random forest classifier\ndefault_grid = {\n    'bootstrap': [True], 'max_depth': [None], 'max_features': ['sqrt'],\n                                      'min_samples_leaf': [1], 'min_samples_split': [2], 'n_estimators': [100]\n}\n\n# X and y data if imputing the training and test set separately\nx_train_decks = prepare_dataframe(train_df, drop_columns_decks).drop([\"Survived\"], axis=1)\ny_train = new_train_df[\"Survived\"]\n\n# X and y data if imputing the training and test set together\n# x_train_decks = prepare_dataframe(combined_df, drop_columns_decks).drop([\"Survived\"], axis=1)[:891]\n# y_train = new_train_df[\"Survived\"]\n\nclf = RandomForestClassifier(n_jobs = -1)\n\nclf_decks = GridSearchCV(estimator = clf, param_grid=grid,\n                       cv = 5, # Setting the test set as the validation set\n                       verbose =1 # Prints out information as it is running\n                       )\n\n# Fit the classifier\nclf_decks.fit(x_train_decks, y_train);\n# Best parameters of the 10 iterations\nbest_params_decks = clf_decks.best_params_\n# Dataframe of the results of each hyperparameter combination\ncv_results_decks = clf_decks.cv_results_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature importance of the quick cross validation shown above","metadata":{}},{"cell_type":"code","source":"# Results of the cross validation\nprint(best_params_decks)\nprint(cv_results_decks[\"mean_test_score\"].mean())\n\n# Dataframe results of the 10 iterations\ncv_results_decks_df = pd.DataFrame(cv_results_decks)\ndisplay(cv_results_decks_df)\n\nimportance = clf_decks.best_estimator_.feature_importances_\n\n# Custom columns to fit in the plot (previous labels too long)\ncolumns = x_train_decks.columns\n\n# Feature importances according to the classifier\nimportance_dictionary = {columns[i] : importance[i] for i in range(len(importance)) }\nimportance\n\nkeys = importance_dictionary.keys()\nvalues = importance_dictionary.values()\n\n# Plot the feature importance\nplt.figure(figsize=(17, 6))\nplt.bar(keys, values)\nplt.xlabel('Features')\nplt.ylabel('Feature Importances')\nplt.title('Feature importance')\nplt.xticks(rotation=45)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exhaustive grid search of the optimal hyperparameters for a Logistic Regression classifier, using cross-validation to minimise overfitting","metadata":{}},{"cell_type":"code","source":"# Import necessary regressors\nfrom sklearn.linear_model import LogisticRegression\n# Setup random seed \nnp.random.seed(42)\n\n# Discluding these features\ndrop_columns_decks = [\"Embarked\", \"Ticket\", \"Name\", \"PassengerId\"]\n\n# Logistic regression hyperparameters to sample from \nlog_grid = {\n    'penalty': ['l1', 'l2'],\n    'C': [0.5, 1, 2, 3],\n    'solver': ['liblinear'],\n    'class_weight': [None, 'balanced'],\n    'max_iter': [2000, 4000],\n    'tol': [0.0001, 0.001, 0.01],\n    'multi_class': ['ovr']\n}\n\n# Creating dataframes\nx_train_decks = prepare_dataframe(train_df, drop_columns_decks).drop([\"Survived\"], axis=1)\ny_train = prepare_dataframe(train_df, drop_columns_decks)['Survived']\nx_test_decks = prepare_dataframe(test_df, drop_columns_decks)\n\n# Instantiating the Logistic regression classifier\nlog_clf = LogisticRegression()\n\n# Setting up randomised search of hyperparameters (considers 10 combinations) with cross validation\ngs_log_clf_decks = GridSearchCV(estimator = log_clf, param_grid=log_grid,\n                       cv = 5, # Setting the test set as the validation set\n                       verbose =1 # Prints out information as it is running\n                       )\n'''\n# Fit the classifier\ngs_log_clf_decks.fit(x_train_decks, y_train);\n# Best parameters of the 10 iterations\nlog_best_params_decks = gs_log_clf_decks.best_params_\n# Dataframe of the results of each hyperparameter combination\nlog_cv_results_decks = gs_log_clf_decks.cv_results_\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Obtain best hyperparameters of the grid search and visualise the feature importances of the best LR classifier","metadata":{}},{"cell_type":"code","source":"'''\n# Results of the cross validation \nprint(log_best_params_decks)\nprint(log_cv_results_decks[\"mean_test_score\"].mean())\n\n# Dataframe results of the 10 iterations\nlog_cv_results_decks_df = pd.DataFrame(log_cv_results_decks)\ndisplay(log_cv_results_decks_df)\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Made my own cross-validation function to be able to produce ROC curves for any of the k-fold classifiers ","metadata":{}},{"cell_type":"code","source":"# Import important functions\nfrom  sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import roc_curve\n\n# Setup random seed\nnp.random.seed(42)\n\n# Function to divide a dataframe into validation and training sets with cross validation (k-folds). Returns the desired fold  \ndef cross_val_index(k_folds, dataframe, fold_number):\n    dataframe.sample(frac=1)\n    x_dataframe = dataframe.drop([\"Survived\"], axis=1)\n    y_dataframe = dataframe[\"Survived\"]\n    \n    index = round(len(x_dataframe)/k_folds)\n    start_index, end_index = [], []\n    for i in range(k_folds):\n                start_index.append(i * index)\n                end_index.append((i + 1) * index if i < k_folds - 1 else len(x_dataframe))\n    print(start_index[fold_number-1], end_index[fold_number-1])\n    X_train = pd.concat([x_dataframe[:start_index[fold_number-1]], x_dataframe[end_index[fold_number-1]:]])\n    y_train = pd.concat([y_dataframe[:start_index[fold_number-1]], y_dataframe[end_index[fold_number-1]:]])\n    X_valid = x_dataframe[start_index[fold_number-1]:end_index[fold_number-1]]\n    y_valid = y_dataframe[start_index[fold_number-1]:end_index[fold_number-1]]\n    print(len(X_valid), len(y_valid))\n    \n    return X_train, y_train, X_valid, y_valid\n\n\n# Columns to drop\ndrop_columns = [\"Embarked\", \"Ticket\", \"Name\", \"PassengerId\"]\n\n# Setting up validation dataframes\nnew_train_df = prepare_dataframe(train_df, drop_columns)\n\n# Calling the function to get the folded dataframes\ncross_val_dataframes = cross_val_index(5, new_train_df, 5)\n\n# Calculating the probabilities of prediction with the best RandomForestClassifier\nbest_clf = RandomForestClassifier( **{'n_estimators': 2000, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 40, 'bootstrap': False})\nbest_clf.fit(cross_val_dataframes[0], cross_val_dataframes[1])\nbest_y_valid_preds = best_clf.predict(cross_val_dataframes[2])\nbest_y_valids_proba = best_clf.predict_proba(cross_val_dataframes[2])\nbest_y_valids_proba_pos = best_y_valids_proba[:, 1]\nprint(accuracy_score(best_y_valid_preds, cross_val_dataframes[3]))\n\n# Calculating the probabilities of prediction with the worst RandomForestClassifier\nworst_clf = RandomForestClassifier( **{'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 40, 'bootstrap': False})\nworst_clf.fit(cross_val_dataframes[0], cross_val_dataframes[1])\nworst_y_valid_preds = worst_clf.predict(cross_val_dataframes[2])\nworst_y_valids_proba = worst_clf.predict_proba(cross_val_dataframes[2])\nworst_y_valids_proba_pos = worst_y_valids_proba[:, 1]\nprint(accuracy_score(worst_y_valid_preds, cross_val_dataframes[3]))\n\n# Calculating the rates and thresholds for the two classifiers\nbest_fpr, best_tpr, best_thresholds = roc_curve(cross_val_dataframes[3].values, best_y_valids_proba_pos)\nworst_fpr, worst_tpr, worst_thresholds = roc_curve(cross_val_dataframes[3].values, worst_y_valids_proba_pos)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ROC curve for the best and worst RF classifiers. \n### It shows the last fold of the five, would have made an average but roc_curve produces a different number of points for each fold","metadata":{}},{"cell_type":"code","source":"# Plotting the ROC curves fo rhte best and worst classifiers \nplt.plot(best_fpr, best_tpr, color='orange', label='ROC')\nplt.plot(worst_fpr, worst_tpr, color='green', label='ROC')\nplt.xlabel('False positive rate (fpr)', size=12)\nplt.ylabel('True positive rate (tpr)', size=12)\nplt.title('Receiver Operating Characteristic (ROC) curve')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating a submission file based on whichever columns, `prepare_dataframe` function, classifier or hyperparameters you would like to consider\n### This version specifically includes almost all the features, imputing the age column with KNN, using a Random Forest classifier and the optimal hyperparameters using a grid search","metadata":{}},{"cell_type":"code","source":"# Dropping only unnecessary columns\ndrop_columns = [\"Embarked\", \"Ticket\", \"Name\", \"PassengerId\"]\n'''\n# Prepare dataframes\nnew_train_df = prepare_dataframe(train_df, drop_columns)\nx_train = new_train_df.drop([\"Survived\"], axis=1)\ny_train = new_train_df[\"Survived\"]\nx_test = prepare_dataframe(test_df, drop_columns)\n'''\n\n# Preparing dataframes with combined imputing\nnew_train_df = prepare_dataframe(combined_df, drop_columns)\nx_train = new_train_df.drop([\"Survived\"], axis=1)[:891]\ny_train = new_train_df[\"Survived\"][:891]\nx_test = new_train_df.drop([\"Survived\"], axis=1)[891:]\n\n# Instantiate Random Forest Classifier with best hyperparameters\nbest_clf = RandomForestClassifier( **{'bootstrap': True, 'max_depth': 10, 'max_features': 'sqrt',\n                                      'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100})\n\n# Fit the classifier and make predictions\nbest_clf.fit(x_train, y_train)\nbest_y_preds = best_clf.predict(x_test).astype(int)\n\n# Create a csv file with the predictions\noutput = gender_submission.copy(deep=True)\noutput['Survived']=best_y_preds\nprint(output)\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating a submission file based on whichever columns, `prepare_dataframe` function, classifier or hyperparameters you would like to consider\n### This version specifically includes almost all the features, imputing the age column with KNN, using a Logistic Regression Model and its respective optimal hyperparameters using a grid search","metadata":{}},{"cell_type":"code","source":"# Dropping only unnecessary columns\ndrop_columns = [\"Embarked\", \"Ticket\", \"Name\", \"PassengerId\"]\n'''\n# Prepare dataframes\nnew_train_df = prepare_dataframe(train_df, drop_columns)\nx_train = new_train_df.drop([\"Survived\"], axis=1)\ny_train = new_train_df[\"Survived\"]\nx_test = prepare_dataframe(test_df, drop_columns)\n'''\n\n# Preparing dataframes with combined imputing\nnew_train_df = prepare_dataframe(combined_df, drop_columns)\nx_train = new_train_df.drop([\"Survived\"], axis=1)[:891]\ny_train = new_train_df[\"Survived\"][:891]\nx_test = new_train_df.drop([\"Survived\"], axis=1)[891:]\n\n# Instantiate Random Forest Classifier with best hyperparameters\nbest_clf = LogisticRegression( **{'C': 2, 'class_weight': None, 'max_iter': 2000, 'multi_class': 'ovr',\n                                 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01})\n\n# Fit the classifier and make predictions\nbest_clf.fit(x_train, y_train)\nbest_y_preds = best_clf.predict(x_test).astype(int)\n\n# Create a csv file with the predictions\noutput = gender_submission.copy(deep=True)\noutput['Survived']=best_y_preds\n# print(output)\n# output.to_csv('submission.csv', index=False)\n# print(\"Your submission was successfully saved!\")\nprint(\"Your submission NOT successfully saved!!!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}