{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30664,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import libraries","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport pandas as pd \nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport sklearn\nimport re \nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.impute import KNNImputer\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nimport scipy\n\nmpl.rcParams['figure.dpi'] = 300\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-28T14:30:12.447304Z","iopub.execute_input":"2024-03-28T14:30:12.447820Z","iopub.status.idle":"2024-03-28T14:30:15.737924Z","shell.execute_reply.started":"2024-03-28T14:30:12.447781Z","shell.execute_reply":"2024-03-28T14:30:15.736592Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Import train, test, gender submission dataframes and visualise data","metadata":{}},{"cell_type":"code","source":"# Load the data\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ngender_submission = pd.read_csv(\"/kaggle/input/titanic/gender_submission.csv\")\n\n# Make dataframes\ntrain_df = pd.DataFrame(train_data)\ntest_df = pd.DataFrame(test_data)\ncombined_df = pd.concat([train_df,test_df], ignore_index=True)\n\n# Set how many rows are shown in the dataframe\npd.set_option('display.min_rows', 10) \npd.set_option('display.max_rows', 10) \n\n# Show the dataframe\ndisplay(combined_df)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T14:30:15.740342Z","iopub.execute_input":"2024-03-28T14:30:15.740981Z","iopub.status.idle":"2024-03-28T14:30:15.820196Z","shell.execute_reply.started":"2024-03-28T14:30:15.740946Z","shell.execute_reply":"2024-03-28T14:30:15.818725Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"      PassengerId  Survived  Pclass  \\\n0               1       0.0       3   \n1               2       1.0       1   \n2               3       1.0       3   \n3               4       1.0       1   \n4               5       0.0       3   \n...           ...       ...     ...   \n1304         1305       NaN       3   \n1305         1306       NaN       1   \n1306         1307       NaN       3   \n1307         1308       NaN       3   \n1308         1309       NaN       3   \n\n                                                   Name     Sex   Age  SibSp  \\\n0                               Braund, Mr. Owen Harris    male  22.0      1   \n1     Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                                Heikkinen, Miss. Laina  female  26.0      0   \n3          Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                              Allen, Mr. William Henry    male  35.0      0   \n...                                                 ...     ...   ...    ...   \n1304                                 Spector, Mr. Woolf    male   NaN      0   \n1305                       Oliva y Ocana, Dona. Fermina  female  39.0      0   \n1306                       Saether, Mr. Simon Sivertsen    male  38.5      0   \n1307                                Ware, Mr. Frederick    male   NaN      0   \n1308                           Peter, Master. Michael J    male   NaN      1   \n\n      Parch              Ticket      Fare Cabin Embarked  \n0         0           A/5 21171    7.2500   NaN        S  \n1         0            PC 17599   71.2833   C85        C  \n2         0    STON/O2. 3101282    7.9250   NaN        S  \n3         0              113803   53.1000  C123        S  \n4         0              373450    8.0500   NaN        S  \n...     ...                 ...       ...   ...      ...  \n1304      0           A.5. 3236    8.0500   NaN        S  \n1305      0            PC 17758  108.9000  C105        C  \n1306      0  SOTON/O.Q. 3101262    7.2500   NaN        S  \n1307      0              359309    8.0500   NaN        S  \n1308      1                2668   22.3583   NaN        C  \n\n[1309 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1304</th>\n      <td>1305</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>Spector, Mr. Woolf</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>A.5. 3236</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1305</th>\n      <td>1306</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>Oliva y Ocana, Dona. Fermina</td>\n      <td>female</td>\n      <td>39.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>PC 17758</td>\n      <td>108.9000</td>\n      <td>C105</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>1306</th>\n      <td>1307</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>Saether, Mr. Simon Sivertsen</td>\n      <td>male</td>\n      <td>38.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>SOTON/O.Q. 3101262</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1307</th>\n      <td>1308</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>Ware, Mr. Frederick</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>359309</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1308</th>\n      <td>1309</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>Peter, Master. Michael J</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2668</td>\n      <td>22.3583</td>\n      <td>NaN</td>\n      <td>C</td>\n    </tr>\n  </tbody>\n</table>\n<p>1309 rows × 12 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"combined_df.info()\ntype(train_df['Ticket'][0])","metadata":{"execution":{"iopub.status.busy":"2024-03-28T14:30:15.821736Z","iopub.execute_input":"2024-03-28T14:30:15.822418Z","iopub.status.idle":"2024-03-28T14:30:15.852284Z","shell.execute_reply.started":"2024-03-28T14:30:15.822378Z","shell.execute_reply":"2024-03-28T14:30:15.851149Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1309 entries, 0 to 1308\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  1309 non-null   int64  \n 1   Survived     891 non-null    float64\n 2   Pclass       1309 non-null   int64  \n 3   Name         1309 non-null   object \n 4   Sex          1309 non-null   object \n 5   Age          1046 non-null   float64\n 6   SibSp        1309 non-null   int64  \n 7   Parch        1309 non-null   int64  \n 8   Ticket       1309 non-null   object \n 9   Fare         1308 non-null   float64\n 10  Cabin        295 non-null    object \n 11  Embarked     1307 non-null   object \ndtypes: float64(3), int64(4), object(5)\nmemory usage: 122.8+ KB\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"str"},"metadata":{}}]},{"cell_type":"markdown","source":"## Visualise differences between male and female survival rates at different ages","metadata":{}},{"cell_type":"code","source":"# Dataframes of male and female survivals\nmale_train_df = train_df.loc[train_df['Sex'] == 'male']\nfemale_train_df = train_df.loc[train_df['Sex'] == 'female']\n\nmale_survived_df = male_train_df.loc[male_train_df['Survived'] == 1]\nmale_died_df = male_train_df.loc[male_train_df['Survived'] == 0]\n\nfemale_survived_df = female_train_df.loc[female_train_df['Survived'] == 1]\nfemale_died_df = female_train_df.loc[female_train_df['Survived'] == 0]\n\n# Initiating the plots\nfig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2, figsize=(14,6), sharex=True)\n\n# Male and female survived histograms, respectively\nhistogram_male_survived = ax0.hist(male_survived_df['Age'], bins=20, alpha=0.5,  label='Survived', color='C0', zorder=1);\nhistogram_male_died = ax0.hist(male_died_df['Age'], bins=20, alpha=0.5,  label='Died', color='C1', zorder=0);\n\nhistogram_female_survived = ax1.hist(female_survived_df['Age'], bins=20, alpha=0.5,  label='Survived');\nhistogram_female_died = ax1.hist(female_died_df['Age'], bins=20, alpha=0.5,  label='Died');\n\n# Add a legend to ax0\nax0.legend()\nax1.legend()\n# Set titles\nax0.set(title='Male', xlabel='Age', ylabel='Number of people');\nax1.set(title='Female', xlabel='Age', ylabel='Number of people');\n# Set labels\nax0.set_xlabel('Age (yrs)', fontsize = 12)\nax0.set_ylabel('Number of people', fontsize = 12)\nax1.set_xlabel('Age (yrs)', fontsize = 12)\nax1.set_ylabel('Number of people', fontsize = 12)","metadata":{"execution":{"iopub.status.busy":"2024-03-26T15:08:07.424893Z","iopub.execute_input":"2024-03-26T15:08:07.425531Z","iopub.status.idle":"2024-03-26T15:08:08.729892Z","shell.execute_reply.started":"2024-03-26T15:08:07.425493Z","shell.execute_reply":"2024-03-26T15:08:08.728823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualise survival rates at different fare prices ","metadata":{}},{"cell_type":"code","source":"# Plot histograms of the number who survived/died according to fare price\nsurvived_df = train_df.loc[train_df['Survived'] == 1]\ndied_df = train_df.loc[train_df['Survived'] == 0]\n\n# Initiating the figures\nfig, ax = plt.subplots(figsize=(14,6))\n\n# Histograms of the survived and died based on fare price\nsurvived_hist = ax.hist(survived_df['Fare'], bins=20, alpha=0.5,  label='Survived', color='C0', zorder=0);\ndied_ = ax.hist(died_df['Fare'], bins=20, alpha=0.5,  label='Died', color='C1', zorder=1);\n\n# Add a legend to ax0\nax.legend()\n# Set labels\nax.set_xlabel('Fare ($)', fontsize = 12)\nax.set_ylabel('Number of people', fontsize = 12)","metadata":{"execution":{"iopub.status.busy":"2024-03-26T15:08:08.732284Z","iopub.execute_input":"2024-03-26T15:08:08.732593Z","iopub.status.idle":"2024-03-26T15:08:09.525848Z","shell.execute_reply.started":"2024-03-26T15:08:08.732566Z","shell.execute_reply":"2024-03-26T15:08:09.524846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pclass1_survive = train_df.loc[(train_df['Survived'] == 1) & (train_df['Pclass'] ==1 )]\npclass1_die = train_df.loc[(train_df['Survived'] == 0) & (train_df['Pclass'] ==1 )]\n\npclass2_survive = train_df.loc[(train_df['Survived'] == 1) & (train_df['Pclass'] ==2 )]\npclass2_die = train_df.loc[(train_df['Survived'] == 0) & (train_df['Pclass'] ==2 )]\n\npclass3_survive = train_df.loc[(train_df['Survived'] == 1) & (train_df['Pclass'] ==3 )]\npclass3_die = train_df.loc[(train_df['Survived'] == 0) & (train_df['Pclass'] ==3 )]\n\nsurvived = [len(pclass1_survive), len(pclass2_survive), len(pclass3_survive)]\ndied = [len(pclass1_die), len(pclass2_die), len(pclass3_die)]\n\nfig, ax = plt.subplots(figsize=(10,4))\n\nx = np.arange(3)\nwidth = 0.4\n\nax.bar(x-0.2, survived, width) \nax.bar(x+0.2, died, width) \nax.set_xticks(x, ['1st', '2nd', '3rd'], size =12) \nax.set_xlabel(\"Passenger Class\", size =12, labelpad=10) \nax.set_ylabel(\"Number of people\", size =12) \nax.legend([\"Survived\", \"Died\"], fontsize =12) ","metadata":{"execution":{"iopub.status.busy":"2024-03-26T15:08:09.527058Z","iopub.execute_input":"2024-03-26T15:08:09.527368Z","iopub.status.idle":"2024-03-26T15:08:10.006112Z","shell.execute_reply.started":"2024-03-26T15:08:09.527341Z","shell.execute_reply":"2024-03-26T15:08:10.005101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Functions to perform feature engineering\n##### `replace_titles` allocates uncommon titles (e.g Major, Capt etc.) to broader title categories (e.g Mr, Ms etc)\n##### `replace_cabin` replaces the cabin codes of passengers with their deck section, denoted by a letter \n##### `add_family` creates a new feature family size which is the total number of siblings/parents/children of a passenger","metadata":{}},{"cell_type":"code","source":"pd.set_option(\"display.max_rows\", 10)\n# New data frame to work with\nnew_train_df = train_df.copy(deep=True)\n\n# Function to create a new column with the title of each passenger\nnew_train_df['Title'] = new_train_df['Name'].map(lambda x: re.compile(\", (.*?)\\.\").findall(x)[0])\n# print(new_train_df['Title'].value_counts())\n\n# Function to allocate uncommon titles to broader title categories\ndef replace_titles(x):\n    title=x['Title']\n    if title in ['Don', 'Major', 'Capt', 'Jonkheer', 'Rev', 'Col', 'Sir']:\n        return 'Mr'\n    elif title in ['the Countess', 'Mme', 'Lady', 'Dona']:\n        return 'Mrs'\n    elif title in ['Mlle', 'Ms']:\n        return 'Miss'\n    elif title =='Dr':\n        if x['Sex']=='Male':\n            return 'Mr'\n        else:\n            return 'Mrs'\n    else:\n        return title\n\ndeck = {\"A\": \"A\", \"B\": \"B\", \"C\": \"C\", \"D\": \"D\", \"E\": \"E\", \"F\": \"F\", \"G\": \"G\", \"U\": \"U\"}\n\n# Function to replace the cabin code with their deck section, denoted by a letter\ndef replace_cabin(x):\n    x['Cabin'] = x['Cabin'].fillna(\"U0\")\n    x['Deck'] = x['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\n    x['Deck'] = x['Deck'].map(deck)\n    x['Deck'] = x['Deck'].fillna(\"U\")\n    x.drop('Cabin',axis=1, inplace=True)\n    \n    return x\n\n# Function to define a person's family size\ndef add_family(x):\n    x['Familysize'] = x['SibSp']+x['Parch']+1\n    return x\n\n# Show the new altered dataframes with 'Title', 'Deck' and 'Familysize' columns\nnew_train_df['Title']=new_train_df.apply(replace_titles, axis=1)\nnew_train_df= replace_cabin(new_train_df)\nnew_train_df = add_family(new_train_df)\n\nnew_train_df","metadata":{"execution":{"iopub.status.busy":"2024-03-26T15:08:10.007597Z","iopub.execute_input":"2024-03-26T15:08:10.008013Z","iopub.status.idle":"2024-03-26T15:08:10.052347Z","shell.execute_reply.started":"2024-03-26T15:08:10.007977Z","shell.execute_reply":"2024-03-26T15:08:10.051338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Function `prepare_dataframe` \n#### It performs all the feature engineering to a dataframe. It uses the previous functions to create new features and imputes missing values","metadata":{}},{"cell_type":"code","source":"# Function to take a dataframe and prepare it for training. It imputes (fills missing values) for\"Age\" and \"Fare\", \n# makes the \"Sex\" column binary (i.e in a cabin or not, male or female) and creates new columns for the passenger Titles, Decks and Family Size.\n# It one hot encodes the \"Embarked\",Title\", \"Deck\" and \"Pclass\" columns. Also removes any unwanted columns specified by drop_columns.\n# \n\ndef prepare_dataframe(df, drop_columns):\n    # Copying dataframe to manipulate\n    new_df = df.copy(deep=True)\n    \n    # Binary mapping the sex column\n    binary_mapping = {\"male\" : 0, \"female\": 1}\n    new_df[\"Sex\"] = new_df[\"Sex\"].map(binary_mapping)\n    \n    # Creating the new Title and Deck columns\n    new_df['Title'] = new_df['Name'].map(lambda x: re.compile(\", (.*?)\\.\").findall(x)[0])\n    new_df['Title'] = new_df.apply(replace_titles, axis=1)\n    \n    # Add a column with their deck section\n    new_df = replace_cabin(new_df)\n    # Add a column with their family size\n    new_df = add_family(new_df)\n    \n    # Numeric and categorical features to encode\n    numeric_features = [\"Fare\"]\n    categorical_features = [\"Embarked\", \"Title\", \"Deck\", 'Pclass']\n    \n    # Strategies for transforming these features\n    numeric_transformer = Pipeline(steps = [(\"imputer\", SimpleImputer(strategy=\"median\"))])\n    \n    categorical_transformer = Pipeline(steps = [ (\"imputer\", SimpleImputer(strategy = \"constant\", \n                                                                           fill_value=\"missing\")),\n                                               (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))])\n    # Transforming these features    \n    preprocessor = ColumnTransformer(transformers = [(\"num\", numeric_transformer, numeric_features),\n                                                    (\"cat\", categorical_transformer, categorical_features)])\n    \n    preprocessor.fit(new_df)\n    \n    transformed_data = preprocessor.transform(new_df)\n    \n    # Getting transformed data and creating new columns to put them in \n    if type(transformed_data[:, :len(numeric_features)]) == scipy.sparse._csr.csr_matrix:\n        numeric_data = transformed_data[:, :len(numeric_features)].toarray()\n        categorical_data = transformed_data[:, len(numeric_features):].toarray()\n    else:\n        numeric_data = transformed_data[:, :len(numeric_features)]\n        categorical_data = transformed_data[:, len(numeric_features):]\n        \n    categorical_encoded_features = preprocessor.named_transformers_['cat']['onehot'] \\\n                                    .get_feature_names_out(input_features=categorical_features)\n    \n    # Replace the columns with transformed data\n    new_df[categorical_encoded_features] = categorical_data\n    new_df[numeric_features] = numeric_data\n    \n    # Impute the missing age data using a KNN algorithm utilising the following features \n    X = new_df[['SibSp', 'Fare', 'Age', 'Title_Master', 'Title_Miss',\n       'Title_Mr', 'Title_Mrs', 'Pclass', 'Sex']]\n\n    impute_knn = KNNImputer()\n    X_imputed = impute_knn.fit_transform(X)\n\n    X_df = pd.DataFrame(X_imputed)\n    age_column = X_df.iloc[:,2]\n    new_df['Age'] = age_column\n    \n    # Removing obsolete features which have been transformed \n    if \"Embarked_missing\" in new_df.columns:\n        new_df.drop(\"Embarked_missing\", axis=1, inplace=True)\n    if \"Title\" in new_df.columns:\n        new_df.drop(\"Title\", axis=1, inplace=True)\n    if \"Deck\" in new_df.columns:\n        new_df.drop(\"Deck\", axis=1, inplace=True)\n    if \"Pclass\" in new_df.columns:\n        new_df.drop(\"Pclass\", axis=1, inplace=True)\n        \n    # Dropping custom columns according to which features we want to include in a model\n    new_df.drop(drop_columns,axis =1, inplace=True)\n    \n    return pd.DataFrame(new_df)","metadata":{"execution":{"iopub.status.busy":"2024-03-26T15:08:10.053761Z","iopub.execute_input":"2024-03-26T15:08:10.054132Z","iopub.status.idle":"2024-03-26T15:08:10.068482Z","shell.execute_reply.started":"2024-03-26T15:08:10.054103Z","shell.execute_reply":"2024-03-26T15:08:10.067434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualise the new dataframe","metadata":{}},{"cell_type":"code","source":"# Custom columns to drop in the function prepare_dataframe\ndrop_columns = [\"Embarked\", \"Ticket\", \"Name\"]\nnew_train_df = prepare_dataframe(train_df, drop_columns)\n# display(new_train_df)\nprint(new_train_df.columns)\nnew_train_df['Age'].isna().sum()\nnew_train_df","metadata":{"execution":{"iopub.status.busy":"2024-03-26T15:08:10.069912Z","iopub.execute_input":"2024-03-26T15:08:10.070228Z","iopub.status.idle":"2024-03-26T15:08:10.207647Z","shell.execute_reply.started":"2024-03-26T15:08:10.070202Z","shell.execute_reply":"2024-03-26T15:08:10.206538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualise the age distributions of the original dataframe (with 177 values missing) and imputed dataframe (using KNN)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:45:25.694631Z","iopub.execute_input":"2024-03-19T11:45:25.695111Z","iopub.status.idle":"2024-03-19T11:45:25.700640Z","shell.execute_reply.started":"2024-03-19T11:45:25.695076Z","shell.execute_reply":"2024-03-19T11:45:25.699472Z"}}},{"cell_type":"code","source":"# Columns to drop in preparing the dataframes\ndrop_columns = [\"Embarked\", \"Ticket\", \"Name\", 'PassengerId']\n\nnew_train_df = prepare_dataframe(train_df, drop_columns)\nnew_test_df = prepare_dataframe(test_df, drop_columns)\n\n#Plotting histograms of the feature variables\nfig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2, figsize = (6,4))\n\n# Create histograms\nax0.hist(train_df[\"Age\"], bins=20);\nax1.hist(new_train_df[\"Age\"], bins=20, );\n\n# Set labels\nax0.set_xlabel('Age (yrs)', fontsize = 12)\nax0.set_ylabel('Number of people', fontsize = 12)\nax1.set_xlabel('Age (yrs)', fontsize = 12)\nax0.set_title('Original dataframe')\nax1.set_title('Imputed dataframe')\nax0.set_ylim(0,140)\nax1.set_ylim(0,140)\n\nprint(new_train_df[\"Age\"].isna().sum())\nprint(train_df[\"Age\"].isna().sum())","metadata":{"execution":{"iopub.status.busy":"2024-03-26T15:08:10.212522Z","iopub.execute_input":"2024-03-26T15:08:10.213220Z","iopub.status.idle":"2024-03-26T15:08:11.054767Z","shell.execute_reply.started":"2024-03-26T15:08:10.213176Z","shell.execute_reply":"2024-03-26T15:08:11.053615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Quick fitting of the data with a default Random forest classifier","metadata":{}},{"cell_type":"code","source":"# Setup the random seed\nnp.random.seed(42)\n\n# Prepare dataframes\nnew_train_df = prepare_dataframe(train_df, drop_columns)\nnew_test_df = prepare_dataframe(test_df, drop_columns)\n\n# First RandomForestClassifier \n\n# Split up into feature variables and target variables\nx_train = new_train_df.drop([\"Survived\"], axis=1)\ny_train = new_train_df[\"Survived\"]\n# Instantiate the classifier\nclf = RandomForestClassifier(n_estimators=100)\nclf.fit(x_train, y_train)\n\n# Predictions of the training data\ny_preds = clf.predict(x_train)\n\nprint(accuracy_score(y_preds, y_train))","metadata":{"execution":{"iopub.status.busy":"2024-03-26T15:08:11.056163Z","iopub.execute_input":"2024-03-26T15:08:11.056492Z","iopub.status.idle":"2024-03-26T15:08:11.485364Z","shell.execute_reply.started":"2024-03-26T15:08:11.056463Z","shell.execute_reply":"2024-03-26T15:08:11.484347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualise the feature importance of the Random forest classifier","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:47:09.399843Z","iopub.execute_input":"2024-03-19T11:47:09.400281Z","iopub.status.idle":"2024-03-19T11:47:09.406481Z","shell.execute_reply.started":"2024-03-19T11:47:09.400251Z","shell.execute_reply":"2024-03-19T11:47:09.404994Z"}}},{"cell_type":"code","source":"# Gives the importance of different features of the model\nimportance = clf.feature_importances_\n\n# Shortened columns to appear on one plot\ncolumns = x_train.columns\n\n# The importance of the different feautures according to the model\nimportance_dictionary = {columns[i] : importance[i] for i in range(len(importance)) }\nprint(importance_dictionary)\n\nkeys = importance_dictionary.keys()\nvalues = importance_dictionary.values()\n\n# Plotting the feature importance\nplt.figure(figsize=(16, 6))\nplt.bar(keys, values)\nplt.xlabel('Features', size=14)\nplt.ylabel('Feature Importances', size=14)\nplt.xticks(rotation=45)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-26T15:08:11.487024Z","iopub.execute_input":"2024-03-26T15:08:11.487439Z","iopub.status.idle":"2024-03-26T15:08:12.362299Z","shell.execute_reply.started":"2024-03-26T15:08:11.487400Z","shell.execute_reply":"2024-03-26T15:08:12.361074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exhaustive grid search of the optimal hyperparameters for a random forest classifier, using cross-validation to minimise overfitting","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:48:53.341156Z","iopub.execute_input":"2024-03-19T11:48:53.341626Z","iopub.status.idle":"2024-03-19T11:48:53.347178Z","shell.execute_reply.started":"2024-03-19T11:48:53.341592Z","shell.execute_reply":"2024-03-19T11:48:53.345974Z"}}},{"cell_type":"code","source":"# Setup the random seed \nnp.random.seed(42)\n\n# # Random forest model discluding all the features below\ndrop_columns_decks = [\"Embarked\", \"Ticket\", \"Name\", 'PassengerId']\n\n# Print which columns we are including \nprint(set(train_df.columns)-set(drop_columns_decks))\n\n# Grid of hyperparameters to sample from\ngrid = {\n    'n_estimators': [100, 500, 1000],\n    'max_depth': [None, 10, 20, 40],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4, 10],\n    'max_features': ['sqrt'],\n    'bootstrap': [True, False]\n}\n\n# Creating dataframes discluding the titles\nx_train_decks = prepare_dataframe(train_df, drop_columns_decks).drop([\"Survived\"], axis=1)\ny_train = new_train_df[\"Survived\"]\nx_test_decks = prepare_dataframe(test_df, drop_columns_decks)\n\n# Instantiating the Random Forest Classifier\nclf = RandomForestClassifier(n_jobs = 1)\n\n# Setting up randomised search of hyperparameters (considers 10 combinations) with cross validation\n'''\nrs_clf_decks = RandomizedSearchCV(estimator = clf, param_distributions=grid,\n                       n_iter = 10, # number of models to try\n                       cv = 5, # Setting the test set as the validation set\n                       verbose =2 # Prints out information as it is running\n                       )\n'''\n'''\n# Setting up exhaustive grid search of hyperparameters (considers 288 combinations) with cross validation\ngs_clf_decks = GridSearchCV(estimator = clf, param_grid=grid,\n                       cv = 5, # Setting the test set as the validation set\n                       verbose =1 # Prints out information as it is running\n                       )\n\n# Fit the classifier\ngs_clf_decks.fit(x_train_decks, y_train);\n# Best parameters of the 10 iterations\nbest_params_decks = gs_clf_decks.best_params_\n# Dataframe of the results of each hyperparameter combination\ncv_results_decks = gs_clf_decks.cv_results_\n'''","metadata":{"execution":{"iopub.status.busy":"2024-03-26T15:08:12.363781Z","iopub.execute_input":"2024-03-26T15:08:12.364307Z","iopub.status.idle":"2024-03-26T15:08:12.514699Z","shell.execute_reply.started":"2024-03-26T15:08:12.364268Z","shell.execute_reply":"2024-03-26T15:08:12.513626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Obtain best hyperparameters of the grid search and visualise the feature importances of the best RF classifier","metadata":{}},{"cell_type":"code","source":"'''\n# Results of the cross validation\nprint(best_params_decks)\nprint(cv_results_decks[\"mean_test_score\"].mean())\n\n# Dataframe results of the 10 iterations\ncv_results_decks_df = pd.DataFrame(cv_results_decks)\ndisplay(cv_results_decks_df)\n\nimportance = gs_clf_decks.best_estimator_.feature_importances_\n\n# Custom columns to fit in the plot (previous labels too long)\ncolumns = x_train_decks.columns\n\n# Feature importances according to the classifier\nimportance_dictionary = {columns[i] : importance[i] for i in range(len(importance)) }\nimportance\n\nkeys = importance_dictionary.keys()\nvalues = importance_dictionary.values()\n\n# Plot the feature importance\nplt.figure(figsize=(17, 6))\nplt.bar(keys, values)\nplt.xlabel('Features')\nplt.ylabel('Feature Importances')\nplt.title('Feature importance')\nplt.show()\n'''","metadata":{"execution":{"iopub.status.busy":"2024-03-26T15:08:12.519752Z","iopub.execute_input":"2024-03-26T15:08:12.520593Z","iopub.status.idle":"2024-03-26T15:08:12.528128Z","shell.execute_reply.started":"2024-03-26T15:08:12.520546Z","shell.execute_reply":"2024-03-26T15:08:12.527128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Perform cross validation with only one hyperparameter combination to quickly see the improvements of any new feature engineering. \n### Can use the default hyperparameters or optimal ones\n","metadata":{}},{"cell_type":"code","source":"np.random.seed(42)\n# Run cross validation on the best hyperparameters to test feature engineering \ndrop_columns_decks = [\"Embarked\", \"Ticket\", \"Name\", 'PassengerId']\n\n# Best hyperparameters according to grid search \ngrid = {\n    'bootstrap': [True], 'max_depth': [10], 'max_features': ['sqrt'],\n                                      'min_samples_leaf': [4], 'min_samples_split': [2], 'n_estimators': [100]\n}\n# Hyperparameters used by default random forest classifier\ndefault_grid = {\n    'bootstrap': [True], 'max_depth': [None], 'max_features': ['sqrt'],\n                                      'min_samples_leaf': [1], 'min_samples_split': [2], 'n_estimators': [100]\n}\n\n# X and y data if imputing the training and test set separately\nx_train_decks = prepare_dataframe(train_df, drop_columns_decks).drop([\"Survived\"], axis=1)\ny_train = new_train_df[\"Survived\"]\n\n# X and y data if imputing the training and test set together\n# x_train_decks = prepare_dataframe(combined_df, drop_columns_decks).drop([\"Survived\"], axis=1)[:891]\n# y_train = new_train_df[\"Survived\"]\n\nclf = RandomForestClassifier(n_jobs = -1)\n\nclf_decks = GridSearchCV(estimator = clf, param_grid=grid,\n                       cv = 5, # Setting the test set as the validation set\n                       verbose =1 # Prints out information as it is running\n                       )\n\n# Fit the classifier\nclf_decks.fit(x_train_decks, y_train);\n# Best parameters of the 10 iterations\nbest_params_decks = clf_decks.best_params_\n# Dataframe of the results of each hyperparameter combination\ncv_results_decks = clf_decks.cv_results_","metadata":{"execution":{"iopub.status.busy":"2024-03-26T15:08:12.530024Z","iopub.execute_input":"2024-03-26T15:08:12.530840Z","iopub.status.idle":"2024-03-26T15:08:14.347748Z","shell.execute_reply.started":"2024-03-26T15:08:12.530783Z","shell.execute_reply":"2024-03-26T15:08:14.346679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature importance of the quick cross validation shown above","metadata":{}},{"cell_type":"code","source":"# Results of the cross validation\nprint(best_params_decks)\nprint(cv_results_decks[\"mean_test_score\"].mean())\n\n# Dataframe results of the 10 iterations\ncv_results_decks_df = pd.DataFrame(cv_results_decks)\ndisplay(cv_results_decks_df)\n\nimportance = clf_decks.best_estimator_.feature_importances_\n\n# Custom columns to fit in the plot (previous labels too long)\ncolumns = x_train_decks.columns\n\n# Feature importances according to the classifier\nimportance_dictionary = {columns[i] : importance[i] for i in range(len(importance)) }\nprint(importance_dictionary)\n\nkeys = importance_dictionary.keys()\nvalues = importance_dictionary.values()\n\n# Plot the feature importance\nplt.figure(figsize=(17, 6))\nplt.bar(keys, values)\nplt.xlabel('Features', size=12)\nplt.ylabel('Feature Importances', size=12)\nplt.title('Feature importance', size=12)\nplt.xticks(rotation=45)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-26T15:08:14.352083Z","iopub.execute_input":"2024-03-26T15:08:14.352404Z","iopub.status.idle":"2024-03-26T15:08:15.349546Z","shell.execute_reply.started":"2024-03-26T15:08:14.352374Z","shell.execute_reply":"2024-03-26T15:08:15.348462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exhaustive grid search of the optimal hyperparameters for a Logistic Regression classifier, using cross-validation to minimise overfitting","metadata":{}},{"cell_type":"code","source":"# Setup random seed \nnp.random.seed(42)\n\n# Discluding these features\ndrop_columns_decks = [\"Embarked\", \"Ticket\", \"Name\", \"PassengerId\"]\n\n# Logistic regression hyperparameters to sample from \nlog_grid = {\n    'penalty': ['l1', 'l2'],\n    'C': [0.5, 1, 2, 3],\n    'solver': ['liblinear'],\n    'class_weight': [None, 'balanced'],\n    'max_iter': [2000, 4000],\n    'tol': [0.0001, 0.001, 0.01],\n    'multi_class': ['ovr']\n}\n\n# Creating dataframes\nx_train_decks = prepare_dataframe(train_df, drop_columns_decks).drop([\"Survived\"], axis=1)\ny_train = prepare_dataframe(train_df, drop_columns_decks)['Survived']\nx_test_decks = prepare_dataframe(test_df, drop_columns_decks)\n\n# Instantiating the Logistic regression classifier\nlog_clf = LogisticRegression()\n\n# Setting up randomised search of hyperparameters (considers 10 combinations) with cross validation\ngs_log_clf_decks = GridSearchCV(estimator = log_clf, param_grid=log_grid,\n                       cv = 5, # Setting the test set as the validation set\n                       verbose =1 # Prints out information as it is running\n                       )\n'''\n# Fit the classifier\ngs_log_clf_decks.fit(x_train_decks, y_train);\n# Best parameters of the 10 iterations\nlog_best_params_decks = gs_log_clf_decks.best_params_\n# Dataframe of the results of each hyperparameter combination\nlog_cv_results_decks = gs_log_clf_decks.cv_results_\n'''","metadata":{"execution":{"iopub.status.busy":"2024-03-26T15:08:15.350874Z","iopub.execute_input":"2024-03-26T15:08:15.351194Z","iopub.status.idle":"2024-03-26T15:08:15.595607Z","shell.execute_reply.started":"2024-03-26T15:08:15.351167Z","shell.execute_reply":"2024-03-26T15:08:15.594415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Obtain best hyperparameters of the grid search and visualise the feature importances of the best LR classifier","metadata":{}},{"cell_type":"code","source":"'''\n# Results of the cross validation \nprint(log_best_params_decks)\nprint(log_cv_results_decks[\"mean_test_score\"].mean())\n\n# Dataframe results of the 10 iterations\nlog_cv_results_decks_df = pd.DataFrame(log_cv_results_decks)\ndisplay(log_cv_results_decks_df)\n'''","metadata":{"execution":{"iopub.status.busy":"2024-03-26T15:08:15.597148Z","iopub.execute_input":"2024-03-26T15:08:15.597553Z","iopub.status.idle":"2024-03-26T15:08:15.608809Z","shell.execute_reply.started":"2024-03-26T15:08:15.597517Z","shell.execute_reply":"2024-03-26T15:08:15.607512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Made my own cross-validation function to be able to produce ROC curves for any of the k-fold classifiers ","metadata":{}},{"cell_type":"code","source":"# Setup random seed\nnp.random.seed(42)\n\n# Function to divide a dataframe into validation and training sets with cross validation (k-folds). Returns the desired fold  \ndef cross_val_index(k_folds, dataframe, fold_number):\n    dataframe.sample(frac=1)\n    x_dataframe = dataframe.drop([\"Survived\"], axis=1)\n    y_dataframe = dataframe[\"Survived\"]\n    \n    index = round(len(x_dataframe)/k_folds)\n    start_index, end_index = [], []\n    for i in range(k_folds):\n                start_index.append(i * index)\n                end_index.append((i + 1) * index if i < k_folds - 1 else len(x_dataframe))\n    print(start_index[fold_number-1], end_index[fold_number-1])\n    X_train = pd.concat([x_dataframe[:start_index[fold_number-1]], x_dataframe[end_index[fold_number-1]:]])\n    y_train = pd.concat([y_dataframe[:start_index[fold_number-1]], y_dataframe[end_index[fold_number-1]:]])\n    X_valid = x_dataframe[start_index[fold_number-1]:end_index[fold_number-1]]\n    y_valid = y_dataframe[start_index[fold_number-1]:end_index[fold_number-1]]\n    \n    return X_train, y_train, X_valid, y_valid\n\n\n# Columns to drop\ndrop_columns = [\"Embarked\", \"Ticket\", \"Name\", \"PassengerId\"]\n\n# Setting up validation dataframes\nnew_train_df = prepare_dataframe(train_df, drop_columns)\n\n# Calling the function to get the folded dataframes\ncross_val_dataframes = cross_val_index(5, new_train_df, 5)\n\n# Calculating the probabilities of prediction with the best RandomForestClassifier\nbest_clf = RandomForestClassifier( **{'bootstrap': True, 'max_depth': 10, 'max_features': 'sqrt',\n                                      'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100})\nbest_clf.fit(cross_val_dataframes[0], cross_val_dataframes[1])\nbest_y_valid_preds = best_clf.predict(cross_val_dataframes[2])\nbest_y_valids_proba = best_clf.predict_proba(cross_val_dataframes[2])\nbest_y_valids_proba_pos = best_y_valids_proba[:, 1]\nprint(accuracy_score(best_y_valid_preds, cross_val_dataframes[3]))\n\n# Calculating the probabilities of prediction with the worst RandomForestClassifier\nworst_clf = RandomForestClassifier( **{'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 40, 'bootstrap': False})\nworst_clf.fit(cross_val_dataframes[0], cross_val_dataframes[1])\nworst_y_valid_preds = worst_clf.predict(cross_val_dataframes[2])\nworst_y_valids_proba = worst_clf.predict_proba(cross_val_dataframes[2])\nworst_y_valids_proba_pos = worst_y_valids_proba[:, 1]\nprint(accuracy_score(worst_y_valid_preds, cross_val_dataframes[3]))\n\n# Calculating the rates and thresholds for the two classifiers\nbest_fpr, best_tpr, best_thresholds = roc_curve(cross_val_dataframes[3].values, best_y_valids_proba_pos)\nworst_fpr, worst_tpr, worst_thresholds = roc_curve(cross_val_dataframes[3].values, worst_y_valids_proba_pos)\n\nprint(roc_auc_score(cross_val_dataframes[3].values, best_y_valids_proba_pos))\nprint(roc_auc_score(cross_val_dataframes[3].values, worst_y_valids_proba_pos))","metadata":{"execution":{"iopub.status.busy":"2024-03-26T15:32:55.900312Z","iopub.execute_input":"2024-03-26T15:32:55.900749Z","iopub.status.idle":"2024-03-26T15:32:57.325868Z","shell.execute_reply.started":"2024-03-26T15:32:55.900713Z","shell.execute_reply":"2024-03-26T15:32:57.324673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ROC curve for the best and worst RF classifiers. \n### It shows the last fold of the five, would have made an average but roc_curve produces a different number of points for each fold","metadata":{}},{"cell_type":"code","source":"# Plotting the ROC curves fo rhte best and worst classifiers \nplt.figure(figsize=(6,4))\nplt.plot(best_fpr, best_tpr, color='orange', label='Best model')\nplt.plot(worst_fpr, worst_tpr, color='green', label='Worst model')\nplt.xlabel('False positive rate (fpr)', size=12)\nplt.ylabel('True positive rate (tpr)', size=12)\nplt.title('Receiver Operating Characteristic (ROC) curve')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-26T15:42:44.018666Z","iopub.execute_input":"2024-03-26T15:42:44.019368Z","iopub.status.idle":"2024-03-26T15:42:44.397650Z","shell.execute_reply.started":"2024-03-26T15:42:44.019320Z","shell.execute_reply":"2024-03-26T15:42:44.396539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating a submission file based on whichever columns, `prepare_dataframe` function, classifier or hyperparameters you would like to consider\n### This version specifically includes almost all the features, imputing the age column with KNN, using a Random Forest classifier and the optimal hyperparameters using a grid search","metadata":{}},{"cell_type":"code","source":"# Dropping only unnecessary columns\ndrop_columns = [\"Embarked\", \"Ticket\", \"Name\", \"PassengerId\"]\n'''\n# Prepare dataframes\nnew_train_df = prepare_dataframe(train_df, drop_columns)\nx_train = new_train_df.drop([\"Survived\"], axis=1)\ny_train = new_train_df[\"Survived\"]\nx_test = prepare_dataframe(test_df, drop_columns)\n'''\n\n# Preparing dataframes with combined imputing\nnew_train_df = prepare_dataframe(combined_df, drop_columns)\nx_train = new_train_df.drop([\"Survived\"], axis=1)[:891]\ny_train = new_train_df[\"Survived\"][:891]\nx_test = new_train_df.drop([\"Survived\"], axis=1)[891:]\n\n# Instantiate Random Forest Classifier with best hyperparameters\nbest_clf = RandomForestClassifier( **{'bootstrap': True, 'max_depth': 10, 'max_features': 'sqrt',\n                                      'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100})\n\n# Fit the classifier and make predictions\nbest_clf.fit(x_train, y_train)\nbest_y_preds = best_clf.predict(x_test).astype(int)\n\n# Create a csv file with the predictions\noutput = gender_submission.copy(deep=True)\noutput['Survived']=best_y_preds\nprint(output)\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"execution":{"iopub.status.busy":"2024-03-26T15:08:20.741761Z","iopub.execute_input":"2024-03-26T15:08:20.742464Z","iopub.status.idle":"2024-03-26T15:08:21.089628Z","shell.execute_reply.started":"2024-03-26T15:08:20.742427Z","shell.execute_reply":"2024-03-26T15:08:21.088512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating a submission file based on whichever columns, `prepare_dataframe` function, classifier or hyperparameters you would like to consider\n### This version specifically includes almost all the features, imputing the age column with KNN, using a Logistic Regression Model and its respective optimal hyperparameters using a grid search","metadata":{}},{"cell_type":"code","source":"# Dropping only unnecessary columns\ndrop_columns = [\"Embarked\", \"Ticket\", \"Name\", \"PassengerId\"]\n'''\n# Prepare dataframes\nnew_train_df = prepare_dataframe(train_df, drop_columns)\nx_train = new_train_df.drop([\"Survived\"], axis=1)\ny_train = new_train_df[\"Survived\"]\nx_test = prepare_dataframe(test_df, drop_columns)\n'''\n\n# Preparing dataframes with combined imputing\nnew_train_df = prepare_dataframe(combined_df, drop_columns)\nx_train = new_train_df.drop([\"Survived\"], axis=1)[:891]\ny_train = new_train_df[\"Survived\"][:891]\nx_test = new_train_df.drop([\"Survived\"], axis=1)[891:]\n\n# Instantiate Random Forest Classifier with best hyperparameters\nbest_clf = LogisticRegression( **{'C': 2, 'class_weight': None, 'max_iter': 2000, 'multi_class': 'ovr',\n                                 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01})\n\n# Fit the classifier and make predictions\nbest_clf.fit(x_train, y_train)\nbest_y_preds = best_clf.predict(x_test).astype(int)\n\n# Create a csv file with the predictions\noutput = gender_submission.copy(deep=True)\noutput['Survived']=best_y_preds\n# print(output)\n# output.to_csv('submission.csv', index=False)\n# print(\"Your submission was successfully saved!\")\nprint(\"Your submission NOT successfully saved!!!\")","metadata":{"execution":{"iopub.status.busy":"2024-03-26T15:08:21.090945Z","iopub.execute_input":"2024-03-26T15:08:21.091212Z","iopub.status.idle":"2024-03-26T15:08:21.207385Z","shell.execute_reply.started":"2024-03-26T15:08:21.091189Z","shell.execute_reply":"2024-03-26T15:08:21.206152Z"},"trusted":true},"execution_count":null,"outputs":[]}]}