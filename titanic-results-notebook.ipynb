{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30664,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Importing modules","metadata":{"execution":{"iopub.status.busy":"2024-03-14T16:54:55.889025Z","iopub.execute_input":"2024-03-14T16:54:55.889536Z","iopub.status.idle":"2024-03-14T16:54:55.895368Z","shell.execute_reply.started":"2024-03-14T16:54:55.889484Z","shell.execute_reply":"2024-03-14T16:54:55.893838Z"}}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport sklearn\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Loading the data","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n# Make a dataframe\ntrain_df = pd.DataFrame(train_data)\ntest_df = pd.DataFrame(test_data)\n\n# Set how many rows are set in the dataframe\npd.set_option('display.min_rows', 10) \npd.set_option('display.max_rows', 10) \n\n# Show the dataframe\ndisplay(train_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Histogram plots of male and female survival rates for different ages","metadata":{"execution":{"iopub.status.busy":"2024-03-14T16:56:02.413019Z","iopub.execute_input":"2024-03-14T16:56:02.413532Z","iopub.status.idle":"2024-03-14T16:56:02.419004Z","shell.execute_reply.started":"2024-03-14T16:56:02.413478Z","shell.execute_reply":"2024-03-14T16:56:02.417736Z"}}},{"cell_type":"code","source":"male_train_df = train_df.loc[train_df['Sex'] == 'male']\nfemale_train_df = train_df.loc[train_df['Sex'] == 'female']\n\nmale_survived_df = male_train_df.loc[male_train_df['Survived'] == 1]\nmale_died_df = male_train_df.loc[male_train_df['Survived'] == 0]\n\nfemale_survived_df = female_train_df.loc[female_train_df['Survived'] == 1]\nfemale_died_df = female_train_df.loc[female_train_df['Survived'] == 0]\n\n\nfig, (ax0,ax1) = plt.subplots(nrows=1, ncols=2, figsize=(14,6), sharex=True)\n\nhistogram_male_survived = ax0.hist(male_survived_df['Age'], bins=20, alpha=0.5,  label='Survived', color='C1', zorder=1);\nhistogram_male_died = ax0.hist(male_died_df['Age'], bins=20, alpha=0.5,  label='Died', color='C0', zorder=0);\n\nhistogram_female_survived = ax1.hist(female_survived_df['Age'], bins=20, alpha=0.5,  label='Survived');\nhistogram_female_died = ax1.hist(female_died_df['Age'], bins=20, alpha=0.5,  label='Died');\n\n# Add a legend to ax0\nax0.legend()\nax1.legend()\n\nax0.set(title='Male', xlabel='Age', ylabel='Number of people');\nax1.set(title='Female', xlabel='Age', ylabel='Number of people');\n\nax0.set_xlabel('Age', fontsize = 12)\nax0.set_ylabel('Number of people', fontsize = 12)\nax1.set_xlabel('Age', fontsize = 12)\nax1.set_ylabel('Number of people', fontsize = 12)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot histograms of the Number who survived/died according to fare price\nsurvived_df = train_df.loc[train_df['Survived'] == 1]\ndied_df = train_df.loc[train_df['Survived'] == 0]\n\nfig, ax = plt.subplots(figsize=(14,6))\n\nsurvived_hist = ax.hist(survived_df['Fare'], bins=20, alpha=0.5,  label='Survived', color='C0', zorder=0);\ndied_ = ax.hist(died_df['Fare'], bins=20, alpha=0.5,  label='Died', color='C1', zorder=1);\n\n# Add a legend to ax0\nax.legend()\n\nax.set_xlabel('Fare', fontsize = 12)\nax.set_ylabel('Number of people', fontsize = 12)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re \n\n# New data frame to work with\nnew_train_df = train_df.copy(deep=True)\n\n# Function to create a new column with the title of each passenger\nnew_train_df['Title'] = new_train_df['Name'].map(lambda x: re.compile(\", (.*?)\\.\").findall(x)[0])\n\n# Allocate uncommon titles to broader title categories\ndef replace_titles(x):\n    title=x['Title']\n    if title in ['Don', 'Major', 'Capt', 'Jonkheer', 'Rev', 'Col', 'Sir']:\n        return 'Mr'\n    elif title in ['the Countess', 'Mme', 'Lady', 'Dona']:\n        return 'Mrs'\n    elif title in ['Mlle', 'Ms']:\n        return 'Miss'\n    elif title =='Dr':\n        if x['Sex']=='Male':\n            return 'Mr'\n        else:\n            return 'Mrs'\n    else:\n        return title\n\ndeck = {\"A\": \"A\", \"B\": \"B\", \"C\": \"C\", \"D\": \"D\", \"E\": \"E\", \"F\": \"F\", \"G\": \"G\", \"U\": \"U\"}\n\n# Function to replace the cabin code with their deck section, denoted by a letter\ndef replace_cabin(x):\n    x['Cabin'] = x['Cabin'].fillna(\"U0\")\n    x['Deck'] = x['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\n    x['Deck'] = x['Deck'].map(deck)\n    x['Deck'] = x['Deck'].fillna(\"U\")\n    x.drop('Cabin',axis=1, inplace=True)\n    \n    return x\n\n# Show the new altered dataframes with 'Title' and 'Deck' columns\nnew_train_df['Title']=new_train_df.apply(replace_titles, axis=1)\nnew_train_df= replace_cabin(new_train_df)\n\nnew_train_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import the methods for pipeline processing\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\n\n# Function to take a dataframe and prepare it for training. It imputes (fills missing values) for\"Age\" and \"Fare\", \n# makes the \"Cabin\" and \"Sex\" column binary (i.e in a cabin or not, male or female) and one hot encodes the \"Embarked\",\n# \"Title\" and \"Deck\" column. \n\ndef prepare_dataframe(df, drop_columns):\n    # Copying dataframe to manipulate\n    new_df = df.copy(deep=True)\n    \n    # Binary mapping the sex column\n    binary_mapping = {\"male\" : 0, \"female\": 1}\n    new_df[\"Sex\"] = new_df[\"Sex\"].map(binary_mapping)\n    \n    # Creating the new Title and Deck columns\n    new_df['Title'] = new_df['Name'].map(lambda x: re.compile(\", (.*?)\\.\").findall(x)[0])\n    new_df['Title'] = new_df.apply(replace_titles, axis=1)\n    \n    new_df = replace_cabin(new_df)\n    \n    # Numeric and categorical features to encode\n    numeric_features = [\"Age\", \"Fare\"]\n    categorical_features = [\"Embarked\", \"Title\", \"Deck\"]\n    \n    # Strategies for transforming these features\n    numeric_transformer = Pipeline(steps = [(\"imputer\", SimpleImputer(strategy=\"mean\"))])\n    \n    categorical_transformer = Pipeline(steps = [ (\"imputer\", SimpleImputer(strategy = \"constant\", \n                                                                           fill_value=\"missing\")),\n                                               (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))])\n    # Transforming these features    \n    preprocessor = ColumnTransformer(transformers = [(\"num\", numeric_transformer, numeric_features),\n                                                    (\"cat\", categorical_transformer, categorical_features)])\n    \n    preprocessor.fit(new_df)\n    \n    transformed_data = preprocessor.transform(new_df)\n    \n    # Getting transformed data and creating new columns to put them in \n    numeric_data = transformed_data[:, :len(numeric_features)].toarray()\n    categorical_data = transformed_data[:, len(numeric_features):].toarray()\n        \n    categorical_encoded_features = preprocessor.named_transformers_['cat']['onehot'] \\\n                                    .get_feature_names_out(input_features=categorical_features)\n    \n    # Replace the columns with transformed data\n    new_df[categorical_encoded_features] = categorical_data\n    new_df[numeric_features] = numeric_data\n    \n    # Removing obsolete features which have been transformed \n    if \"Embarked_missing\" in new_df.columns:\n        new_df.drop(\"Embarked_missing\", axis=1, inplace=True)\n    if \"Title\" in new_df.columns:\n        new_df.drop(\"Title\", axis=1, inplace=True)\n    if \"Deck\" in new_df.columns:\n        new_df.drop(\"Deck\", axis=1, inplace=True)\n    \n    # Dropping custom columns according to which features we want to include in a model\n    new_df.drop(drop_columns,axis =1, inplace=True)\n    \n    return pd.DataFrame(new_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Custom columns to drop in the function prepare_dataframe\ndrop_columns = [\"Embarked\", \"Ticket\", \"Name\", \"PassengerId\"]\nnew_train_df = prepare_dataframe(train_df, drop_columns)\ndisplay(new_train_df)\nnew_train_df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Columns to drop in preparing the dataframes\ndrop_columns = [\"Embarked\", \"Ticket\", \"Name\", \"PassengerId\"]\n\nnew_train_df = prepare_dataframe(train_df, drop_columns)\nnew_test_df = prepare_dataframe(test_df, drop_columns)\n\n#Plotting histograms of the feature variables\nfig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2, figsize = (8,5))\n\n# Create histograms\nax0.hist(train_df[\"Age\"], bins=20);\nax1.hist(new_train_df[\"Age\"], bins=20);\n\n# Set labels\nax0.set_xlabel('Age', fontsize = 12)\nax0.set_ylabel('Number of people', fontsize = 12)\nax1.set_xlabel('Age', fontsize = 12)\nax0.set_title('Original dataframe')\nax1.set_title('Imputed dataframe')\n\nprint(new_train_df[\"Age\"].isna().sum())\nprint(train_df[\"Age\"].isna().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Quick fitting of the data\nfrom sklearn.metrics import accuracy_score\n\n# Setup the random seed\nnp.random.seed(42)\n\n# Prepare dataframes\nnew_train_df = prepare_dataframe(train_df, drop_columns)\nnew_test_df = prepare_dataframe(test_df, drop_columns)\n\n# First RandomForestClassifier \n\n# Split up into feature variables and target variables\nx_train = new_train_df.drop([\"Survived\"], axis=1)\ny_train = new_train_df[\"Survived\"]\nx_test = new_test_df\n\n# Import randomforestclassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Instantiate the classifier\nclf = RandomForestClassifier(n_estimators=100)\nclf.fit(x_train, y_train)\n\n# Predictions of the training data\ny_preds = clf.predict(x_train)\n\nprint(accuracy_score(y_preds, y_train))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Gives the importance of different features of the model\nimportance = clf.feature_importances_\n\n# Shortened columns to appear on one plot\ncolumns = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Emb_C',\n       'Emb_Q', 'Emb_S', 'Master', 'Miss', 'Mr',\n       'Mrs', 'Deck_A', 'Deck_B', 'Deck_C', 'Deck_D', 'Deck_E', 'Deck_F',\n       'Deck_G', 'Deck_U']\n\n# The importance of the different feautures according to the model\nimportance_dictionary = {columns[i] : importance[i] for i in range(len(importance)) }\nimportance\n\nkeys = importance_dictionary.keys()\nvalues = importance_dictionary.values()\n\n# Plotting the feature importance\nplt.figure(figsize=(16, 6))\nplt.bar(keys, values)\nplt.xlabel('Features', size=12)\nplt.ylabel('Feature Importances', size=12)\nplt.title('Feature importance')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import important modules\nfrom  sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import PredefinedSplit\nfrom sklearn.base import clone\n\n# Setup Random Seed\nnp.random.seed(42)\n\n# Random Forest model, not including all the features below\ndrop_columns_cabin = [\"Embarked\", \"Ticket\", \"Name\", \"PassengerId\", 'Title_Master',\n       'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Deck_A', 'Deck_B', 'Deck_C', 'Deck_D',\n       'Deck_E', 'Deck_F', 'Deck_G', 'Deck_U']\n\n# Print which columns we are including \nprint(set(original_columns)-set(drop_columns_cabin))\n\n# Grid of hyperparameters to sample from\ngrid = {\n    'n_estimators': [100, 500, 1000, 2000],\n    'max_depth': [None, 10, 20, 40],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4],\n    'max_features': ['sqrt'],\n    'bootstrap': [True, False]\n}\n \n\n# Setup the random seed\nnp.random.seed(42)\n\n# Creating dataframes discluding the cabins and titles \nx_train_cabin = prepare_dataframe(train_df, drop_columns_cabin).drop([\"Survived\"], axis=1)\ny_train = new_train_df[\"Survived\"]\nx_test_cabin = prepare_dataframe(test_df, drop_columns_cabin)\n\n# Instantiating Random forest classifier\nclf = RandomForestClassifier(n_jobs = 1)\n\n# Setting up randomised search of hyperparameters (considers 10 combinations) with cross validation\nrs_clf = RandomizedSearchCV(estimator = clf, param_distributions=grid,\n                       n_iter = 10, # number of models to try\n                       cv = 5, # Setting the test set as the validation set\n                       verbose =2 # Prints out logs as it is running\n                       )\n# Fit the classifier\nrs_clf.fit(x_train_cabin, y_train);\n# Best parameters of the 10 iterations\nbest_params_cabin = rs_clf.best_params_\n# Dataframe of the results of each hyperparameter combination\ncv_results_cabin = rs_clf.cv_results_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Results of the cross validation \npd.set_option('display.min_rows', 20) \npd.set_option('display.max_rows', 20) \n\n# The best performing parameter, and the mean score of the 10 combinations\nprint(best_params_cabin)\nprint(cv_results_cabin_df[\"mean_test_score\"].mean())\n\n# Results of the 10 iterations\ncv_results_cabin_df = pd.DataFrame(cv_results_cabin)\ndisplay(cv_results_cabin_df)\n\n# Feature importances according to the classifier\nimportance = rs_clf.best_estimator_.feature_importances_\nimportance_dictionary = {x_train_cabin.columns[i] : importance[i] for i in range(len(importance)) }\n\nkeys = importance_dictionary.keys()\nvalues = importance_dictionary.values()\n\n# Plot the feature importance\nplt.figure(figsize=(16, 6))\nplt.bar(keys, values)\nplt.xlabel('Features')\nplt.ylabel('Feature Importances')\nplt.title('Feature importance')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setup the random seed\nnp.random.seed(42)\n\n# Random forest model not discluding all the features below\ndrop_columns_titles = [\"Embarked\", \"Ticket\", \"Name\", \"PassengerId\", 'Deck_A', 'Deck_B', 'Deck_C', 'Deck_D', \\\n       'Deck_E', 'Deck_F', 'Deck_G', 'Deck_U']\n\n# Print which columns we are including \nprint(set(original_columns)-set(drop_columns_titles))\n\n# Grid of hyperparameters to sample from\ngrid = {\n    'n_estimators': [100, 500, 1000, 2000],\n    'max_depth': [None, 10, 20, 40],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4],\n    'max_features': ['sqrt'],\n    'bootstrap': [True, False]\n}\n \n# Creating dataframes discluding the titles\nx_train_titles = prepare_dataframe(train_df, drop_columns_titles).drop([\"Survived\"], axis=1)\ny_train = new_train_df[\"Survived\"]\nx_test_titles = prepare_dataframe(test_df, drop_columns_titles)\n\n# Instantiating the Random Forest Classifier\nclf = RandomForestClassifier(n_jobs = 1)\n\n# Setting up randomised search of hyperparameters (considers 10 combinations) with cross validation\nrs_clf_titles = RandomizedSearchCV(estimator = clf, param_distributions=grid,\n                       n_iter = 10, # number of models to try\n                       cv = 5, # Setting the test set as the validation set\n                       verbose =2 # Prints out information as it is running\n                       )\n# Fit the classifier\nrs_clf_titles.fit(x_train_titles, y_train);\n# Best parameters of the 10 iterations\nbest_params_titles = rs_clf_titles.best_params_\n# Dataframe of the results of each hyperparameter combination\ncv_results_titles = rs_clf_titles.cv_results_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Results of the cross validation \nprint(best_params_titles)\nprint(cv_results_titles_df[\"mean_test_score\"].mean())\n\n# Dataframe results of the 10 iterations\ncv_results_titles_df = pd.DataFrame(cv_results_titles)\ndisplay(cv_results_titles_df)\n\n\n# Feature importances according to the classifier\nimportance = rs_clf_titles.best_estimator_.feature_importances_\nimportance_dictionary = {x_train_titles.columns[i] : importance[i] for i in range(len(importance)) }\n\nkeys = importance_dictionary.keys()\nvalues = importance_dictionary.values()\n\n# Plot the feature importance\nplt.figure(figsize=(17, 6))\nplt.bar(keys, values)\nplt.xlabel('Features')\nplt.ylabel('Feature Importances')\nplt.title('Feature importance')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setup the random seed \nnp.random.seed(42)\n\n# # Random forest model discluding all the features below\ndrop_columns_decks = [\"Embarked\", \"Ticket\", \"Name\", \"PassengerId\"]\n\n# Print which columns we are including \nprint(set(original_columns)-set(drop_columns_decks))\n\n# Grid of hyperparameters to sample from\ngrid = {\n    'n_estimators': [100, 500, 1000, 2000],\n    'max_depth': [None, 10, 20, 40],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4],\n    'max_features': ['sqrt'],\n    'bootstrap': [True, False]\n}\n\n# Creating dataframes discluding the titles\nx_train_decks = prepare_dataframe(train_df, drop_columns_decks).drop([\"Survived\"], axis=1)\ny_train = new_train_df[\"Survived\"]\nx_test_decks = prepare_dataframe(test_df, drop_columns_decks)\n\n# Instantiating the Random Forest Classifier\nclf = RandomForestClassifier(n_jobs = 1)\n\n# Setting up randomised search of hyperparameters (considers 10 combinations) with cross validation\nrs_clf_decks = RandomizedSearchCV(estimator = clf, param_distributions=grid,\n                       n_iter = 10, # number of models to try\n                       cv = 5, # Setting the test set as the validation set\n                       verbose =2 # Prints out information as it is running\n                       )\n# Fit the classifier\nrs_clf_decks.fit(x_train_decks, y_train);\n# Best parameters of the 10 iterations\nbest_params_decks = rs_clf_decks.best_params_\n# Dataframe of the results of each hyperparameter combination\ncv_results_decks = rs_clf_decks.cv_results_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Results of the cross validation\nprint(best_params_decks)\nprint(cv_results_decks_df[\"mean_test_score\"].mean())\n\n# Dataframe results of the 10 iterations\ncv_results_decks_df = pd.DataFrame(cv_results_decks)\ndisplay(cv_results_decks_df)\n\nimportance = rs_clf_decks.best_estimator_.feature_importances_\n\n# Custom columns to fit in the plot (previous labels too long)\ncolumns = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Emb_C',\n       'Emb_Q', 'Emb_S', 'Master', 'Miss', 'Mr',\n       'Mrs', 'Deck_A', 'Deck_B', 'Deck_C', 'Deck_D', 'Deck_E', 'Deck_F',\n       'Deck_G', 'Deck_U']\n\n# Feature importances according to the classifier\nimportance_dictionary = {columns[i] : importance[i] for i in range(len(importance)) }\nimportance\n\nkeys = importance_dictionary.keys()\nvalues = importance_dictionary.values()\n\n# Plot the feature importance\nplt.figure(figsize=(17, 6))\nplt.bar(keys, values)\nplt.xlabel('Features')\nplt.ylabel('Feature Importances')\nplt.title('Feature importance')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import important functions\nfrom  sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import roc_curve\n\n# Setup random seed\nnp.random.seed(42)\n\n# Function to divide a dataframe into validation and training sets with cross validation (k-folds). Returns the desired fold  \ndef cross_val_index(k_folds, x_dataframe, y_dataframe, fold_number):\n    index = round(len(x_dataframe)/k_folds)\n    start_index, end_index = [], []\n    for i in range(k_folds):\n                start_index.append(i * index)\n                end_index.append((i + 1) * index if i < k_folds - 1 else len(x_dataframe))\n    print(start_index[fold_number-1], end_index[fold_number-1])\n    X_train = pd.concat([x_dataframe[:start_index[fold_number-1]], x_dataframe[end_index[fold_number-1]:]])\n    y_train = pd.concat([y_dataframe[:start_index[fold_number-1]], y_dataframe[end_index[fold_number-1]:]])\n    X_valid = x_dataframe[start_index[fold_number-1]:end_index[fold_number-1]]\n    y_valid = y_dataframe[start_index[fold_number-1]:end_index[fold_number-1]]\n    print(len(X_valid), len(y_valid))\n    \n    return X_train, y_train, X_valid, y_valid\n\n\n\ndrop_columns = [\"Embarked\", \"Ticket\", \"Name\", \"PassengerId\"]\n\n# Setting up validation dataframes\nnew_train_df = prepare_dataframe(train_df, drop_columns)\nx_train = new_train_df.drop([\"Survived\"], axis=1)\ny_train = new_train_df[\"Survived\"]\n\ncross_val_dataframes = cross_val_index(5, x_train, y_train, 5)\n\n# Calculating the probabilities of prediction with the best RandomForestClassifier\nbest_clf = RandomForestClassifier( **{'n_estimators': 2000, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 40, 'bootstrap': False})\nbest_clf.fit(cross_val_dataframes[0], cross_val_dataframes[1])\nbest_y_valid_preds = best_clf.predict(cross_val_dataframes[2])\nbest_y_valids_proba = best_clf.predict_proba(cross_val_dataframes[2])\nbest_y_valids_proba_pos = best_y_valids_proba[:, 1]\nprint(accuracy_score(best_y_valid_preds, cross_val_dataframes[3]))\n\n# Calculating the probabilities of prediction with the worst RandomForestClassifier\nworst_clf = RandomForestClassifier( **{'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 40, 'bootstrap': False})\nworst_clf.fit(cross_val_dataframes[0], cross_val_dataframes[1])\nworst_y_valid_preds = worst_clf.predict(cross_val_dataframes[2])\nworst_y_valids_proba = worst_clf.predict_proba(cross_val_dataframes[2])\nworst_y_valids_proba_pos = worst_y_valids_proba[:, 1]\nprint(accuracy_score(worst_y_valid_preds, cross_val_dataframes[3]))\n\n# Calculating the rates and thresholds for the two classifiers\nbest_fpr, best_tpr, best_thresholds = roc_curve(cross_val_dataframes[3].values, best_y_valids_proba_pos)\nworst_fpr, worst_tpr, worst_thresholds = roc_curve(cross_val_dataframes[3].values, worst_y_valids_proba_pos)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the ROC curves fo rhte best and worst classifiers \nplt.plot(best_fpr, best_tpr, color='orange', label='ROC')\nplt.plot(worst_fpr, worst_tpr, color='green', label='ROC')\nplt.xlabel('False positive rate (fpr)')\nplt.ylabel('True positive rate (tpr)')\nplt.title('Receiver Operating Characteristic (ROC) curve')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Submitting a prediction \n\n# Dropping only unnecessary columns\ndrop_columns = [\"Embarked\", \"Ticket\", \"Name\", \"PassengerId\"]\n\n# Prepare dataframes\nnew_train_df = prepare_dataframe(train_df, drop_columns)\nx_train = new_train_df.drop([\"Survived\"], axis=1)\ny_train = new_train_df[\"Survived\"]\nx_test = prepare_dataframe(test_df, drop_columns)\n\n# Instantiate Random Forest Classifier with best hyperparameters\nbest_clf = RandomForestClassifier( **{'n_estimators': 2000, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 40, 'bootstrap': False})\nbest_clf.fit(x_train, y_train)\nbest_y_preds = best_clf.predict(x_test)\n\n# Fit the classifier and make predictions\nclf.fit(x_train, y_train)\nbest_y_preds = clf.predict(x_test)\n\n# Create a csv file with the predictions\noutput = pd.DataFrame({'PassengerId': test_df.PassengerId, 'Survived': best_y_preds})\nprint(output)\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Quick fitting of the data for a logistic regression model \n\nnew_train_df = prepare_dataframe(train_df, drop_columns)\nnew_test_df = prepare_dataframe(test_df, drop_columns)\n\n# First RandomForestClassifier \n\n# Setup the random seed\nnp.random.seed(42)\n\n# Split up into feature variables and target variables\nx_train = new_train_df.drop([\"Survived\"], axis=1)\ny_train = new_train_df[\"Survived\"]\nx_test = new_test_df\n\n# Import randomforestclassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\n# Instantiate the classifier\nlog_clf = LogisticRegression(max_iter=1000)\nlog_clf.fit(x_train, y_train)\n\ny_preds = clf.predict(x_train)\n\nprint(accuracy_score(y_preds, y_train))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Submitting the basic logistic regression classifier \nlog_y_preds = log_clf.predict(x_test)\n\noutput = pd.DataFrame({'PassengerId': test_df.PassengerId, 'Survived': log_y_preds})\nprint(output)\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setup random seed \nnp.random.seed(42)\n\n# Discluding these features\ndrop_columns_decks = [\"Embarked\", \"Ticket\", \"Name\", \"PassengerId\"]\n\n# Logistic regression hyperparameters to sample from \nlog_grid = {\n    'penalty': ['l1', 'l2'],\n    'C': [1, 5, 10, 100],\n    'solver': ['liblinear'],\n    'class_weight': [None, 'balanced'],\n    'max_iter': [2000, 4000],\n    'tol': [0.0001, 0.001, 0.01],\n    'multi_class': ['ovr']\n}\n\n# Creating dataframes\nx_train_decks = prepare_dataframe(train_df, drop_columns_decks).drop([\"Survived\"], axis=1)\ny_train = new_train_df[\"Survived\"]\nx_test_decks = prepare_dataframe(test_df, drop_columns_decks)\n\n# Instantiating the Logistic regression classifier\nlog_clf = LogisticRegression()\n\n# Setting up randomised search of hyperparameters (considers 10 combinations) with cross validation\nrs_log_clf_decks = RandomizedSearchCV(estimator = log_clf, param_distributions=log_grid,\n                       n_iter = 10, # number of models to try\n                       cv = 5, # Setting the test set as the validation set\n                       verbose =2 # Prints out information as it is running\n                       )\n# Fit the classifier\nrs_log_clf_decks.fit(x_train_decks, y_train);\n# Best parameters of the 10 iterations\nlog_best_params_decks = rs_log_clf_decks.best_params_\n# Dataframe of the results of each hyperparameter combination\nlog_cv_results_decks = rs_log_clf_decks.cv_results_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Results of the cross validation \nprint(log_best_params_decks)\nprint(log_cv_results_decks_df[\"mean_test_score\"].mean())\n\n# Dataframe results of the 10 iterations\nlog_cv_results_decks_df = pd.DataFrame(log_cv_results_decks)\ndisplay(log_cv_results_decks_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Submitting predictions for the logistic regression model \ndrop_columns = [\"Embarked\", \"Ticket\", \"Name\", \"PassengerId\"]\n\n# Creating the dataframes\nnew_train_df = prepare_dataframe(train_df, drop_columns)\nx_train = new_train_df.drop([\"Survived\"], axis=1)\ny_train = new_train_df[\"Survived\"]\nx_test = prepare_dataframe(test_df, drop_columns)\n\n# Picking the best hyperparameters and fitting the model\nbest_log_clf = LogisticRegression( **{'tol': 0.0001, 'solver': 'liblinear', 'penalty': 'l1', 'multi_class': 'ovr', 'max_iter': 2000, 'class_weight': None, 'C': 1})\nbest_log_clf.fit(x_train, y_train)\nbest_log_y_preds = best_log_clf.predict(x_test)\n\n# Creating a csv file with the predictions \noutput = pd.DataFrame({'PassengerId': test_df.PassengerId, 'Survived': best_log_y_preds})\nprint(output)\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}